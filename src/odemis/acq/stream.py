# -*- coding: utf-8 -*-
"""
:created: 22 Feb 2013
:author: Rinze de Laat
:copyright: © 2013 Rinze de Laat, Delmic

This file is part of Odemis.

.. license::
    Odemis is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License version 2 as published
    by the Free Software Foundation.

    Odemis is distributed in the hope that it will be useful, but WITHOUT ANY
    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
    FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
    details.

    You should have received a copy of the GNU General Public License along with
    Odemis. If not, see http://www.gnu.org/licenses/.



This module contains classes that describe Streams, which are basically
Detector, Emitter and Dataflow associations.

"""

from __future__ import division

from abc import ABCMeta, abstractmethod
import collections
from concurrent.futures._base import CancelledError, CANCELLED, FINISHED, \
    RUNNING
import logging
import math
import numpy
from odemis.acq import calibration, _futures
from odemis.acq import drift as acq_drift
from odemis.model import VigilantAttribute, MD_POS, MD_PIXEL_SIZE, MD_DESCRIPTION
from odemis.util import TimeoutError, limit_invocation, polar, spectrum
import threading
import time

import odemis.model as model
import odemis.util.conversion as conversion
import odemis.util.img as img
import odemis.util.units as units
from odemis.acq import find_overlay

# to identify a ROI which must still be defined by the user
UNDEFINED_ROI = (0, 0, 0, 0)

# Maximum allowed overlay difference in electron coordinates #m
OVRL_MAX_DIFF = 1e-06

#pylint: disable=W0221

class Stream(object):
    """ A stream combines a Detector, its associated Dataflow and an Emitter.

    It handles acquiring the data from the hardware and renders it as a RGB
    image (with MD_PIXEL_SIZE and MD_POS copied)

    This is an abstract class, unless the emitter doesn't need any configuration
    (always on, with the right settings).

    Note: If a Stream needs multiple Emitters, then this should be implemented
    in a subclass of Stream.
    """

    WARNING_EXCITATION_NOT_OPT = ("The excitation wavelength selected cannot "
                                  "be optimally generated by the hardware.")
    WARNING_EXCITATION_IMPOSSIBLE = ("The excitation wavelength selected "
                                     "cannot be generated by the hardware.")
    WARNING_EMISSION_NOT_OPT = ("The emission wavelength selected cannot be "
                                "optimally detected by the hardware.")
    WARNING_EMISSION_IMPOSSIBLE = ("The emission wavelength selected cannot be "
                                   "detected by the hardware.")

    # Minimum overhead time in seconds when acquiring an image
    SETUP_OVERHEAD = 0.1

    def __init__(self, name, detector, dataflow, emitter):
        """
        name (string): user-friendly name of this stream
        detector (Detector): the detector which has the dataflow
        dataflow (Dataflow): the dataflow from which to get the data
        emitter (Emitter): the emitter
        """

        self.name = model.StringVA(name)

        # Hardware Components
        self._detector = detector
        self._emitter = emitter

        # Dataflow (Live image stream with meta data)
        # Note: A Detectors can have multiple dataflows, so that's why a Stream
        # has a separate attribute.
        self._dataflow = dataflow

        # TODO: this flag is horrendous as it can lead to not updating the image
        # with the latest image. We need to reorganise everything so that the
        # image display is done via a dataflow (in a separate thread), instead
        # of a VA.
        self._running_upd_img = False # to avoid simultaneous updates in different threads
        # list of DataArray received and used to generate the image
        # every time it's modified, image is also modified
        self.raw = []
        # the most important attribute
        self.image = model.VigilantAttribute(None)

        # TODO: should maybe to 2 methods activate/deactivate to explicitly
        # start/stop acquisition, and one VA "updated" to stated that the user
        # want this stream updated (as often as possible while other streams are
        # also updated)
        # should_update has no effect direct effect, it's just a flag to
        # indicate the user would like to have the stream updated (live)
        self.should_update = model.BooleanVA(False)
        # is_active set to True will keep the acquisition going on
        self.is_active = model.BooleanVA(False)
        self.is_active.subscribe(self.onActive)

        # Region of interest as left, top, right, bottom (in ratio from the
        # whole area of the emitter => between 0 and 1)
        self.roi = model.TupleContinuous((0, 0, 1, 1),
                                         range=((0, 0, 0, 0), (1, 1, 1, 1)),
                                         cls=(int, long, float))

        self._irange = None
        self._updateIRange()

        # whether to use auto brightness & contrast
        self.auto_bc = model.BooleanVA(True)
        # % of values considered outliers discarded in auto BC detection
        # Note: 1/256th is a nice value because on RGB, it means in degenerated
        # cases (like flat histogram), you still loose only one value on each
        # side.
        self.auto_bc_outliers = model.FloatContinuous(100 / 256, range=(0, 40))

        # Used if auto_bc is False
        # min/max ratio of the whole intensity level which are mapped to
        # black/white. The .histogram always has
        # the first value mapped to 0 and last value mapped to 1.
        self.intensityRange = model.TupleContinuous((0, 1),
                                                    range=((0, 0), (1, 1)),
                                                    cls=(int, long, float))

        # Histogram of the current image _or_ slightly older image.
        # Note it's an ndarray. Use .tolist() to get a python list.
        self.histogram = model.VigilantAttribute(numpy.ndarray(0), readonly=True)
        self.histogram._full_hist = numpy.ndarray(0) # for finding the outliers
        self.histogram._edges = self._irange # TODO: needed?

        self.auto_bc.subscribe(self._onAutoBC)
        self.auto_bc_outliers.subscribe(self._onOutliers) # FIXME
        self.intensityRange.subscribe(self._onIntensityRange)
        self._ht_needs_recompute = threading.Event()
        self._htread = threading.Thread(target=self._histogram_thread,
                                        name="Histogram computation")
        self._htread.daemon = True
        self._htread.start()

        # self.histogram.subscribe(self._onHistogram) # FIXME -> update outliers and then image

        # list of warnings to display to the user
        # TODO should be a set
        self.warnings = model.ListVA([]) # should only contain WARNING_*

    @property
    def emitter(self):
        return self._emitter

    def __str__(self):
        return "%s %s" % (self.__class__.__name__, self.name.value)

    def estimateAcquisitionTime(self):
        """ Estimate the time it will take to acquire one image with the current
        settings of the detector and emitter.

        returns (float): approximate time in seconds that acquisition will take
        """
        # This default implementation returns the shortest possible time, taking
        # into account a minimum overhead. (As in, acquisition will never take
        # less than 0.1 seconds)
        return self.SETUP_OVERHEAD

    def _removeWarnings(self, *warnings):
        """ Remove all the given warnings if any are present

        warnings (set of WARNING_*): the warnings to remove
        """
        new_warnings = set(self.warnings.value) - set(warnings)
        self.warnings.value = list(new_warnings)

    def _addWarning(self, warning):
        """ Add a warning if not already present

        warning (WARNING_*): the warning to add
        """
        if not warning in self.warnings.value:
            self.warnings.value.append(warning)

    def onActive(self, active):
        """ Called when the Stream is activated or deactivated by setting the
        is_active attribute
        """
        if active:
            msg = "Subscribing to dataflow of component %s"
            logging.debug(msg, self._detector.name)
            if not self.should_update.value:
                logging.warning("Trying to activate stream while it's not "
                                "supposed to update")
            self._dataflow.subscribe(self.onNewImage)
        else:
            msg = "Unsubscribing from dataflow of component %s"
            logging.debug(msg, self._detector.name)
            self._dataflow.unsubscribe(self.onNewImage)

    # No __del__: subscription should be automatically stopped when the object
    # disappears, and the user should stop the update first anyway.

    def _updateIRange(self, data=None):
        """
        Update the ._irange, with whatever data is known so far.
        data (None or DataArray): data on which to base the detection. If None,
          it will try to use .raw, and if there is nothing, will just use the
          detector information.
        """
        # 2 types of irange management:
        # * dtype is int -> follow MD_BPP/shape/dtype.max
        # * dtype is float -> always increase, starting from 0-depth
        if data is None:
            if self.raw:
                data = self.raw[0]

        if data is not None:
            if data.dtype.kind in "biu":
                try:
                    depth = 2**data.metadata[model.MD_BPP]
                    if depth <= 1:
                        logging.warning("Data reports a BPP of %d",
                                        data.metadata[model.MD_BPP])
                        raise ValueError()

                    if data.dtype.kind == "i":
                        irange = (-depth // 2, depth // 2 - 1)
                    else:
                        irange = (0, depth - 1)
                except (KeyError, ValueError):
                    try:
                        depth = self._detector.shape[-1]
                        if depth <= 1:
                            logging.warning("Detector %s report a depth of %d",
                                             self._detector.name, depth)
                            raise ValueError()

                        if data.dtype.kind == "i":
                            irange = (-depth // 2, depth // 2 - 1)
                        else:
                            irange = (0, depth - 1)
                    except (AttributeError, IndexError, ValueError):
                        idt = numpy.iinfo(data.dtype)
                        irange = (idt.min, idt.max)
            else: # float
                # cast to ndarray to ensure a scalar (instead of a DataArray)
                irange = (numpy.array(data).min(), numpy.array(data).max())
                if self._irange is not None:
                    irange = (min(irange[0], self._irange[0]),
                              max(irange[1], self._irange[1]))
        else:
            # no data, assume it's uint
            try:
                # The last element of the shape indicates the bit depth, which
                # is used for brightness/contrast adjustment.
                depth = self._detector.shape[-1]
                if depth <= 1:
                    logging.warning("Detector %s report a depth of %d",
                                     self._detector.name, depth)
                    raise ValueError()
                irange = (0, depth - 1)
            except (AttributeError, IndexError, ValueError):
                irange = None

        self._irange = irange

    def _getDisplayIRange(self):
        """
        return the min/max values to display. It also updates the intensityRange
         VA if needed.
        """
        if self.auto_bc.value:
            # The histogram might be slightly old, but not too much
            irange = img.findOptimalRange(self.histogram._full_hist,
                                          self.histogram._edges,
                                          self.auto_bc_outliers.value / 100)

            # Also update the intensityRanges if auto BC
            edges = self.histogram._edges
            rrange = [(v - edges[0]) / (edges[1] - edges[0]) for v in irange]
            self.intensityRange.value = tuple(rrange)
        else:
            # just convert from the user-defined (as ratio) to actual values
            rrange = sorted(self.intensityRange.value)
            edges = self.histogram._edges
            irange = [edges[0] + (edges[1] - edges[0]) * v for v in rrange]

        return irange

    def _find_metadata(self, data):
        """
        Find the PIXEL_SIZE and POS metadata from the given raw image
        return (dict MD_* -> value)
        """
        md = data.metadata
        try:
            pos = md[model.MD_POS]
        except KeyError:
            # Note: this log message is disabled to prevent log flooding
            # logging.warning("Position of image unknown")
            pos = (0, 0)

        try:
            pxs = md[model.MD_PIXEL_SIZE]
        except KeyError:
            # Hopefully it'll be within the same magnitude
            # default to typical sensor size
            spxs = md.get(model.MD_SENSOR_PIXEL_SIZE, (20e-6, 20e-6))
            binning = md.get(model.MD_BINNING, (1, 1))
            pxs = spxs[0] / binning[0], spxs[1] / binning[1]
            # Note: this log message is disabled to prevent log flooding
            # msg = "Pixel density of image unknown, using sensor size"
            # logging.warning(msg)

        # Not necessary, but handy to debug latency problems
        try:
            date = md[model.MD_ACQ_DATE]
        except KeyError:
            date = time.time()

        return {model.MD_PIXEL_SIZE: pxs,
                model.MD_POS: pos,
                model.MD_ACQ_DATE: date}

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self, tint=(255, 255, 255)):
        """ Recomputes the image with all the raw data available

        tint ((int, int, int)): colouration of the image, in RGB. Only used by
            FluoStream to avoid code duplication
        """
        # check to avoid running it if there is already one running
        if self._running_upd_img:
            logging.debug("Dropping image conversion to RGB, as the previous one is still running")
            return
        if not self.raw:
            return

        try:
            self._running_upd_img = True
            data = self.raw[0]
            irange = self._getDisplayIRange()
            rgbim = img.DataArray2RGB(data, irange, tint)
            rgbim.flags.writeable = False
            if model.MD_ACQ_DATE in data.metadata:
                logging.debug("Computed RGB projection %g s after acquisition",
                               time.time() - data.metadata[model.MD_ACQ_DATE])
            self.image.value = model.DataArray(rgbim, self._find_metadata(data))
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)
        finally:
            self._running_upd_img = False

    def _onAutoBC(self, enabled):
        # if changing to auto: B/C might be different from the manual values
        if enabled == True:
            self._updateImage()

    def _onOutliers(self, outliers):
        if self.auto_bc.value == True:
            self._updateImage()

    def _onIntensityRange(self, irange):
        # If auto_bc is active, it updates intensities (from _updateImage()),
        # so no need to refresh image again.
        if self.auto_bc.value == False:
            self._updateImage()

    def _shouldUpdateHistogram(self):
        """
        Ensures that the histogram VA will be updated in the "near future".
        """
        # If the previous request is still being processed, the event
        # synchronization allows to delay it (without accumulation).
        self._ht_needs_recompute.set()

    def _updateHistogram(self, data=None):
        """
        data (DataArray): the raw data to use, default to .raw[0]
        """
        # Compute histogram and compact version
        if not self.raw and not data:
            return

        data = self.raw[0] if data is None else data
        # Initially, _irange might be None, in which case it will be guessed
        hist, edges = img.histogram(data, irange=self._irange)
        if hist.size > 256:
            chist = img.compactHistogram(hist, 256)
        else:
            chist = hist
        self.histogram._full_hist = hist
        self.histogram._edges = edges
        # Read-only VA, so we need to go around...
        self.histogram._value = chist
        self.histogram.notify(chist)

    def _histogram_thread(self):
        """
        Called as a separate thread, and recomputes the histogram whenever
        it receives an event asking for it.
        """
        while True:
            self._ht_needs_recompute.wait() # wait until a new image is available
            tstart = time.time()
            self._ht_needs_recompute.clear()
            self._updateHistogram()
            tend = time.time()

            # sleep at as much, to ensure we are not using too much CPU
            tsleep = max(0.2, tend - tstart) # max 5 Hz
            time.sleep(tsleep)

    def onNewImage(self, dataflow, data):
        # For now, raw images are pretty simple: we only have one
        # (in the future, we could keep the old ones which are not fully
        # overlapped)

        if model.MD_ACQ_DATE in data.metadata:
            logging.debug("Receive raw %g s after acquisition",
                           time.time() - data.metadata[model.MD_ACQ_DATE])

        old_irange = self._irange
        if not self.raw:
            self.raw.append(data)
            old_irange = None # will force histogram creation
        else:
            self.raw[0] = data

        # Depth can change at each image (depends on hardware settings)
        self._updateIRange()
        if old_irange != self._irange:
            logging.debug("Updating irange to %s", self._irange)
            # This ensures there's always a valid histogram
            self._updateHistogram()
        else:
            self._shouldUpdateHistogram()

        self._updateImage()


class SEMStream(Stream):
    """ Stream containing images obtained via Scanning electron microscope.

    It basically knows how to activate the scanning electron and the detector.
    """
    def __init__(self, name, detector, dataflow, emitter):
        Stream.__init__(self, name, detector, dataflow, emitter)

        # TODO: drift correction
        # .driftCorrection: Boolean
        # .driftROI: the region used for the drift correction
        # .driftCorrectionPeriod: time in s between each correction (approximate
        #   ,tries to do it after every N lines, or every N pixels)
        # Need to see

        # TODO: Anti-aliasing/Pixel fuzzing
        # .fuzzing: boolean
        # Might be better to automatically activate it for Spectrum, and disable
        # it for AR (without asking the user)

        try:
            self._prevDwellTime = emitter.dwellTime.value
            emitter.dwellTime.subscribe(self.onDwellTime)
        except AttributeError:
            # if emitter has no dwell time -> no problem
            pass

        # Actually use the ROI
        self.roi.subscribe(self._onROI)

        # Spot mode: when set (and stream is active), it will drive the e-beam
        # do only the center of the scanning area. Image is not updated.
        # TODO: is this the right interface? Shall we just have a different
        # stream type?
        self.spot = model.BooleanVA(False)

        # used to reset the previous settings after spot mode
        self._no_spot_settings = (None, None, None) # dwell time, resolution, translation
        self.spot.subscribe(self._onSpot)

        # drift correction VAs:
        # dcRegion defines the anchor region, drift correction will be disabled
        #   if it is set to UNDEFINED_ROI
        # dcDwellTime: dwell time used when acquiring anchor region
        # dcPeriod is the (approximate) time between two acquisition of the
        #  anchor (and drift compensation). The exact period is determined so
        #  that it fits with the region of acquisition.
        # Note: the scale used for the acquisition of the anchor region is the
        #  same as the scale of the SEM. We could add a dcScale if it's needed.
        self.dcRegion = model.TupleContinuous(UNDEFINED_ROI,
                                         range=((0, 0, 0, 0), (1, 1, 1, 1)),
                                         cls=(int, long, float),
                                         setter=self._setDCRegion)
        self.dcDwellTime = model.FloatContinuous(emitter.dwellTime.range[0],
                                         range=emitter.dwellTime.range, unit="s")
        self.dcPeriod = model.FloatContinuous(60,  # s, default to one minute
                                              range=[0.1, 1e6], unit="s")

    def _onROI(self, roi):
        """
        Update the scanning area of the SEM according to the roi
        """
        # only change hw settings if stream is active (and not spot mode)
        # Note: we could also (un)subscribe whenever these changes, but it's
        # simple like this.
        if not self.is_active.value or self.spot.value:
            return

        # We should remove res setting from the GUI when this ROI is used.
        center = ((roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2)
        width = (roi[2] - roi[0], roi[3] - roi[1])

        shape = self._emitter.shape
        # translation is distance from center (situated at 0.5, 0.5), can be floats
        trans = (shape[0] * (center[0] - 0.5), shape[1] * (center[1] - 0.5))
        # resolution is the maximum resolution at the scale in proportion of the width
        scale = self._emitter.scale.value
        res = (max(1, int(round(shape[0] * width[0] / scale[0]))),
               max(1, int(round(shape[1] * width[1] / scale[1]))))

        # always in this order
        self._emitter.resolution.value = res
        self._emitter.translation.value = trans

    def _setDCRegion(self, roi):
        """
        Called when the dcRegion is set
        """
        logging.debug("dcRegion set to %s", roi)
        if roi == UNDEFINED_ROI:
            return roi # No need to discuss it

        width = [roi[2] - roi[0], roi[3] - roi[1]]
        center = [(roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2]

        # Ensure the ROI is at least as big as the MIN_RESOLUTION
        # (knowing it always uses scale = 1)
        shape = self._emitter.shape
        min_width = [r / s for r, s in zip(acq_drift.MIN_RESOLUTION, shape)]
        width = [max(a, b) for a, b in zip(width, min_width)]

        # Recompute the ROI so that it fits
        roi = (center[0] - width[0] / 2, center[1] - width[1] / 2,
               center[0] + width[0] / 2, center[1] + width[1] / 2)
        if roi[0] < 0:
            center[0] += roi[0]
        elif roi[2] > 1:
            center[0] -= roi[2] - 1
        if roi[1] < 0:
            center[1] += roi[1]
        elif roi[3] > 1:
            center[3] -= roi[3] - 1
        roi = (center[0] - width[0] / 2, center[1] - width[1] / 2,
               center[0] + width[0] / 2, center[1] + width[1] / 2)

        return roi

    def _onSpot(self, active):
        if active:
            self._startSpot()
        else:
            self._stopSpot()

    def _startSpot(self):
        """
        Start the spot mode. Can handle being called if it's already active
        """
        if self._no_spot_settings != (None, None, None):
            logging.debug("Starting spot mode while it was already active")
            return

        # to be avoid potential weird scanning while changing values
        self._dataflow.unsubscribe(self.onNewImage)

        logging.debug("Activating spot mode")
        self._no_spot_settings = (self._emitter.dwellTime.value,
                                  self._emitter.resolution.value,
                                  self._emitter.translation.value)

        # resolution -> translation: order matters
        self._emitter.resolution.value = (1, 1)
        self._emitter.translation.value = (0, 0) # position of the spot (floats)

        # put a not too short dwell time to avoid acquisition to keep repeating,
        # and not too long to avoid using too much memory for acquiring one point.
        self._emitter.dwellTime.value = 0.1 # s

        if self.is_active.value:
            self._dataflow.subscribe(self.onNewImage)

    def _stopSpot(self):
        """
        Stop the spot mode. Can handle being called if it's already inactive
        """
        if self._no_spot_settings == (None, None, None):
            logging.debug("Stop spot mode while it was already inactive")
            return

        # to be avoid potential weird scanning while changing values
        self._dataflow.unsubscribe(self.onNewImage)

        logging.debug("Disabling spot mode")

        (self._emitter.dwellTime.value,
         self._emitter.resolution.value,
         self._emitter.translation.value) = self._no_spot_settings

        self._no_spot_settings = (None, None, None)

        if self.is_active.value:
            self._dataflow.subscribe(self.onNewImage)

    def estimateAcquisitionTime(self):

        try:
            res = list(self._emitter.resolution.value)
            # Typically there is few more pixels inserted at the beginning of
            # each line for the settle time of the beam. We guesstimate by just
            # adding 1 pixel to each line
            if len(res) == 2:
                res[1] += 1
            else:
                logging.warning(("Resolution of scanner is not 2 dimensional, "
                                 "time estimation might be wrong"))
            # Each pixel x the dwell time in seconds
            duration = self._emitter.dwellTime.value * numpy.prod(res)
            # Add the setup time
            duration += self.SETUP_OVERHEAD

            return duration
        # TODO: Remove 'catch-all' with realistic exception
        except Exception:  #pylint: disable=W0703
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

    def onActive(self, active):
        if active:
            # TODO: if can blank => unblank

            # update hw settings to our own ROI
            self._onROI(self.roi.value)

            if self.dcRegion.value != UNDEFINED_ROI:
                raise NotImplementedError("SEM drift correction on simple SEM "
                                          "acquisition not yet implemented")

        # handle spot mode
        if self.spot.value:
            if active:
                self._startSpot()
            else:
                self._stopSpot()
        super(SEMStream, self).onActive(active)

    def onDwellTime(self, value):
        # When the dwell time changes, the new value is only used on the next
        # acquisition. Assuming the change comes from the user (very likely),
        # then if the current acquisition would take a long time, cancel it, and
        # restart acquisition so that the new value is directly used. The main
        # goal is to avoid cases where user mistakenly put a 10+ s acquisition,
        # and it takes ages to get back to a faster acquisition. Note: it only
        # works if we are the only subscriber (but that's very likely).

        try:
            if self.is_active.value == False:
                # not acquiring => nothing to do
                return

            # approximate time for the current image acquisition
            res = self._emitter.resolution.value
            prevDuration = self._prevDwellTime * numpy.prod(res)

            if prevDuration < 1:
                # very short anyway, not worthy
                return

            # TODO: do this on a rate-limited fashion (now, or ~1s)
            # unsubscribe, and re-subscribe immediately
            self._dataflow.unsubscribe(self.onNewImage)
            self._dataflow.subscribe(self.onNewImage)

        finally:
            self._prevDwellTime = value

    def onNewImage(self, df, data):
        """

        """
        # In spot mode, don't update the image.
        # (still receives data as the e-beam needs an active detector to acquire)
        if self.spot.value:
            return
        super(SEMStream, self).onNewImage(df, data)

class CameraStream(Stream):
    """ Abstract class representing streams which have a digital camera as a
    detector.

    Mostly used to share time estimation only.
    """
    def estimateAcquisitionTime(self):
        # exposure time + readout time * pixels (if CCD) + set-up time
        try:
            exp = self._detector.exposureTime.value
            res = self._detector.resolution.value
            if isinstance(self._detector.readoutRate,
                          model.VigilantAttributeBase):
                readout = 1 / self._detector.readoutRate.value
            else:
                # let's assume it's super fast
                readout = 0

            duration = exp + numpy.prod(res) * readout + self.SETUP_OVERHEAD
            return duration
        except:
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

    def _stop_light(self):
        """
        Ensures the light is turned off (temporarily)
        """
        # Just change the intensity of each wavelengths, so that the power is
        # recorded.
        emissions = [0] * len(self._emitter.emissions.value)
        self._emitter.emissions.value = emissions

        # TODO: might need to be more clever to avoid turning off and on the
        # light source when just switching between FluoStreams. => have a
        # global acquisition manager which takes care of switching on/off
        # the emitters which are used/unused.


class BrightfieldStream(CameraStream):
    """ Stream containing images obtained via optical brightfield illumination.

    It basically knows how to select white light and disable any filter.
    """

    def onActive(self, active):
        if active:
            self._setup_excitation()
            # TODO: do we need to have a special command to disable filter??
            # or should it be disabled automatically by the other streams not
            #using it?
            # self._setup_emission()
        else:
            self._stop_light()
        Stream.onActive(self, active)

    # def _setup_emission(self):
    #     if not self._filter.band.readonly:
    #         raise NotImplementedError("Do not know how to change filter band")

    def _setup_excitation(self):
        # TODO: how to select white light??? We need a brightlight hardware?
        # Turn on all the sources? Does this always mean white?
        # At least we should set a warning if the final emission range is quite
        # different from the normal white spectrum
        em = [1] * len(self._emitter.emissions.value)
        self._emitter.emissions.value = em

class CameraNoLightStream(CameraStream):
    """ Stream containing images obtained via optical CCD but without any light
     source on. Used for the SECOM lens alignment tab.

    It basically knows how to turn off light and remove position information.
    """
    def __init__(self, name, detector, dataflow, emitter, position=None):
        """
        position (VA of dict str -> float): stage position to use instead of the
         position contained in the metadata.
        """
        self._position = position
        CameraStream.__init__(self, name, detector, dataflow, emitter)
        self._prev_light_power = self._emitter.power.value

    def onActive(self, active):
        # TODO: use _stop_light()
        if active:
            # turn off the light
            self._prev_light_power = self._emitter.power.value
            self._emitter.power.value = 0
        else:
            # restore the light
            # TODO: not necessary if each stream had its own hardware settings
            self._emitter.power.value = self._prev_light_power
        Stream.onActive(self, active)

    def _find_metadata(self, data):
        """
        Find the PIXEL_SIZE and POS metadata from the given raw image
        return (dict MD_* -> value)
        """
        # Override the normal metadata by using the ._position we know
        md = super(CameraNoLightStream, self)._find_metadata(data)

        try:
            if self._position:
                pos = self._position.value # a stage should always have x,y axes
                md[MD_POS] = pos["x"], pos["y"]
        except Exception:
            logging.exception("Failed to get X/Y position")

        return md

class FluoStream(CameraStream):
    """ Stream containing images obtained via epifluorescence.

    It basically knows how to select the right emission/filtered wavelengths,
    and how to taint the image.

    Note: Excitation is (filtered) light coming from a light source and
    emission is the light emitted by the sample.
    """

    def __init__(self, name, detector, dataflow, emitter, em_filter):
        """
        name (string): user-friendly name of this stream
        detector (Detector): the detector which has the dataflow
        dataflow (Dataflow): the dataflow from which to get the data
        emitter (Light): the HwComponent to modify the light excitation
        filter (Filter): the HwComponent to modify the emission light filtering
        """
        CameraStream.__init__(self, name, detector, dataflow, emitter)
        self._em_filter = em_filter

        # TODO: instead of defining the excitation and emission wavelengths,
        # just give the user the same choice as the hardware, and the user
        # has to pick the right value (and the GUI can start with an
        # "informed guess").

        # This is what is displayed to the user
        # Default to the center of the first excitation and emission bands
        exc_range = [min([s[0] for s in emitter.spectra.value]),
                     max([s[4] for s in emitter.spectra.value])]
        self.excitation = model.FloatContinuous(emitter.spectra.value[0][2],
                                                range=exc_range, unit="m")
        self.excitation.subscribe(self.onExcitation)

        # The wavelength band on the out path (set when emission changes)
        bands = em_filter.axes["band"].choices
        cur_pos = em_filter.position.value["band"]
        self._current_out_wl = bands[cur_pos]
        em_range = self._find_emission_range(bands.values())
        self.emission = model.FloatContinuous(em_range[0] + 1e-9,
                                              range=em_range, unit="m")
        self.emission.subscribe(self.onEmission)

        # colouration of the image
        default_tint = conversion.wave2rgb(self.emission.value)
        self.tint = model.ListVA(default_tint, unit="RGB") # 3-tuple R,G,B
        self.tint.subscribe(self.onTint)

    def onActive(self, active):
        if active:
            self._setup_excitation()
            self._setup_emission()
        else:
            self._stop_light() # important if SEM image to be acquired
        Stream.onActive(self, active)

    def _updateImage(self): #pylint: disable=W0221
        Stream._updateImage(self, self.tint.value)

    def onExcitation(self, value):
        if self.is_active.value:
            self._setup_excitation()

    def onEmission(self, value):
        if self.is_active.value:
            self._setup_emission()

    def onTint(self, value):
        if self.raw:
            data = self.raw[0]
            data.metadata[model.MD_USER_TINT] = value

        self._updateImage()

    def _find_emission_range(self, bands):
        """
        return (float, float): min/max wavelength
        """
        lows, highs = [], []
        # if multi-band: get the range of all
        for b in bands:
            if isinstance(b[0], collections.Iterable):
                rng = self._find_emission_range(b)
            else:
                rng = b
            lows.append(rng[0])
            highs.append(rng[1])

        return min(lows), max(highs)

    def _find_best_emission_band(self, wl):
        """
        wl (float): wavelength (in m)
        return (int): the position corresponding to the best band
        """
        # The most fitting band: narrowest band centered around the wavelength
        bands = self._em_filter.axes["band"].choices
        def quantify_fit(wl, band):
            """ Quantifies how well the given wavelength matches the given
            band: the better the match, the higher the return value will be.
            wl (float): Wavelength to quantify
            band ((list of) 2-tuple floats): The band(s)
            return (0<float): the more, the merrier
            """
            # if multi-band: get the best of all
            if isinstance(band[0], collections.Iterable):
                return max(quantify_fit(wl, b) for b in band)

            if band[0] < wl < band[1]:
                distance = abs(wl - numpy.mean(band)) # distance to center
                width = band[1] - band[0]
                # ensure it cannot get infinite score for being in the center
                return 1 / (max(distance, 1e-9) * max(width, 1e-9))
            elif band[0] - 20e-9 < wl < band[1] + 20e-9:
                # almost? => 100x less good
                distance = abs(wl - numpy.mean(band)) # distance to center
                width = band[1] - band[0]
                return 0.01 / (max(distance, 1e-9) * max(width, 1e-9))
            else:
                # No match
                return 0

        scores = dict((k, quantify_fit(wl, v)) for k, v in bands.items())
        # key with best score
        best, score = max(scores.items(), key=lambda x: x[1])
        if score == 0:
            return None
        return best

    def _setup_emission(self):
        """
        Set-up the hardware for the right emission light (light path between
        the sample and the CCD), and check whether the emission value matches
        the emission filter bands.
        """
        wl = self.emission.value

        p = self._find_best_emission_band(wl)
        self._removeWarnings(Stream.WARNING_EMISSION_IMPOSSIBLE,
                             Stream.WARNING_EMISSION_NOT_OPT)
        if p is not None:
            f = self._em_filter.moveAbs({"band": p})
            bands = self._em_filter.axes["band"].choices[p]
            self._current_out_wl = bands

            # Detect if the selected band is outside of wl
            if not isinstance(bands[0], collections.Iterable):
                bands = [bands] # force it to be a list of bands
            for l, h in bands:
                if l < wl < h:
                    break
            else:
                self._addWarning(Stream.WARNING_EMISSION_NOT_OPT)
                # TODO: add the actual band in the warning message?

            f.result() # wait for the move to be finished
        else:
            logging.warning("Emission wavelength %s doesn't fit the filter",
                            units.readable_str(wl, "m"))
            self._addWarning(Stream.WARNING_EMISSION_IMPOSSIBLE)

        return

    def _setup_excitation(self):
        """ Set-up the excitation light to the specified wavelength (light path
        between the light source and the sample), and check whether this
        actually can work.
        """
        wave_length = self.excitation.value

        def quantify_fit(wl, spec):
            """ Quantifies how well the given wavelength matches the given
            spectrum: the better the match, the higher the return value will be.
            wl (float): Wavelength to quantify
            spec (5-tuple float): The spectrum to check the wavelength against
            return (0<float): the more, the merrier
            """
            if spec[0] < wl < spec[4]:
                distance = abs(wl - spec[2]) # distance to 100%
                if distance:
                    return 1 / distance
                # No distance, ultimate match
                return float("inf")
            else:
                # No match
                return 0

        spectra = self._emitter.spectra.value
        # arg_max with quantify_fit function as key
        best = max(spectra, key=lambda x: quantify_fit(wave_length, x))
        i = spectra.index(best)

        # create an emissions with only one source active, which best matches
        # the excitation wavelength
        emissions = [0] * len(spectra)
        emissions[i] = 1
        self._emitter.emissions.value = emissions

        # TODO: read back self._emitter.emissions.value to get the actual value
        # set warnings if necessary
        self._removeWarnings(Stream.WARNING_EXCITATION_IMPOSSIBLE,
                             Stream.WARNING_EXCITATION_NOT_OPT)

        # TODO: if the band is too wide (e.g., white), it should also have a
        # warning
        # TODO: if the light can only be changed manually, display a warning
        if wave_length < best[0] or wave_length > best[4]:
            # outside of band
            self._addWarning(Stream.WARNING_EXCITATION_IMPOSSIBLE)
        elif wave_length < best[1] or wave_length > best[3]:
            # outside of main 50% band
            self._addWarning(Stream.WARNING_EXCITATION_NOT_OPT)

    def onNewImage(self, dataflow, data):
        # Add some metadata on the fluorescence

        # TODO: handle better if there is already MD_OUT_WL
        data.metadata[model.MD_OUT_WL] = self._current_out_wl

        data.metadata[model.MD_USER_TINT] = self.tint.value
        super(FluoStream, self).onNewImage(dataflow, data)


class RepetitionStream(Stream):
    """
    Abstract class for streams which are actually a set multiple acquisition
    repeated over a grid.
    """

    def __init__(self, name, detector, dataflow, emitter):
        self.name = model.StringVA(name)

        # Hardware Components
        self._detector = detector # the spectrometer
        self._emitter = emitter # the e-beam
        # To acquire simultaneously other detector (ex: SEM secondary electrons)
        # a separate stream must be used, and the acquisition manager will take
        # care of doing both at the same time

        # data-flow of the spectrometer
        self._dataflow = dataflow

        self.raw = [] # to contain data during acquisition (from MD streams)

        # all the information needed to acquire an image (in addition to the
        # hardware component settings which can be directly set).

        # ROI + repetition is sufficient, but pixel size is nicer for the user
        # and allow us to ensure each pixel is square. (Non-square pixels are
        # not a problem for the hardware, but annoying to display data in normal
        # software).

        # We ensure in the setters that all the data is always consistent:
        # roi set: roi + pxs → repetition + roi + pxs
        # pxs set: roi + pxs → repetition + roi (small changes)
        # repetition set: repetition + roi + pxs → repetition + pxs + roi (small changes)

        # Region of interest as left, top, right, bottom (in ratio from the
        # whole area of the emitter => between 0 and 1)
        self.roi = model.TupleContinuous((0, 0, 1, 1),
                                         range=[(0, 0, 0, 0), (1, 1, 1, 1)],
                                         cls=(int, long, float),
                                         setter=self._setROI)
        # the number of pixels acquired in each dimension
        # it will be assigned to the resolution of the emitter (but cannot be
        # directly set, as one might want to use the emitter while configuring
        # the stream).
        self.repetition = model.ResolutionVA(emitter.resolution.value,
                                             emitter.resolution.range,
                                             setter=self._setRepetition)

        # the size of the pixel, horizontally and vertically
        # actual range is dynamic, as it changes with the magnification
        self.pixelSize = model.FloatContinuous(emitter.pixelSize.value[0],
                           range=[0, 1], unit="m", setter=self._setPixelSize)

        # exposure time of each pixel is the exposure time of the detector,
        # the dwell time of the emitter will be adapted before acquisition.

        # Update the pixel size whenever SEM magnification changes
        # This allows to keep the ROI at the same place in the SEM FoV.
        # Note: this is to be done only if the user needs to manually update the
        # magnification.
        self._prev_mag = emitter.magnification.value
        emitter.magnification.subscribe(self._onMagnification)

    def _onMagnification(self, mag):
        """
        Called when the SEM magnification is updated
        """
        # Update the pixel size so that the ROI stays that the same place in the
        # SEM FoV and with the same repetition.
        # The bigger is the magnification, the smaller should be the pixel size
        ratio = self._prev_mag / mag
        self.pixelSize._value *= ratio
        self.pixelSize.notify(self.pixelSize._value)

    def _updateROIAndPixelSize(self, roi, pxs):
        """
        roi : ROI wanted (might be slightly changed)
        pxs (float): new pixel size (must be within allowed range, always respected)
        Returns new ROI and repetition
        """
        # If ROI is undefined => everything is fine
        if roi == UNDEFINED_ROI:
            return roi, self.repetition.value

        epxs = self.emitter.pixelSize.value
        eshape = self.emitter.shape
        phy_size = [epxs[0] * eshape[0], epxs[1] * eshape[1]] # max physical ROI

        # maximum repetition: either depends on minimum pxs or maximum roi
        roi_size = [roi[2] - roi[0], roi[3] - roi[1]]
        max_rep = [max(1, min(int(eshape[0] * roi_size[0]), int(phy_size[0] / pxs))),
                   max(1, min(int(eshape[1] * roi_size[1]), int(phy_size[1] / pxs)))]

        # compute the repetition (ints) that fits the ROI with the pixel size
        rep = [round(phy_size[0] * roi_size[0] / pxs),
               round(phy_size[1] * roi_size[1] / pxs)]
        rep = [int(max(1, min(rep[0], max_rep[0]))),
               int(max(1, min(rep[1], max_rep[1])))]

        # update the ROI so that it's _exactly_ pixel size * repetition,
        # while keeping its center fixed
        roi_center = [(roi[0] + roi[2]) / 2,
                      (roi[1] + roi[3]) / 2]
        roi_size = [rep[0] * pxs / phy_size[0],
                    rep[1] * pxs / phy_size[1]]
        roi = [roi_center[0] - roi_size[0] / 2,
               roi_center[1] - roi_size[1] / 2,
               roi_center[0] + roi_size[0] / 2,
               roi_center[1] + roi_size[1] / 2]

        # shift the ROI if it's now slightly outside the possible area
        if roi[0] < 0:
            roi[2] = min(1, roi[2] - roi[0])
            roi[0] = 0
        elif roi[2] > 1:
            roi[0] = max(0, roi[0] - (roi[2] - 1))
            roi[2] = 1

        if roi[1] < 0:
            roi[3] = min(1, roi[3] - roi[1])
            roi[1] = 0
        elif roi[3] > 1:
            roi[1] = max(0, roi[1] - (roi[3] - 1))
            roi[3] = 1

        return tuple(roi), tuple(rep)

    def _setROI(self, roi):
        """
        Ensures that the ROI is always an exact number of pixels, and update
         repetition to be the correct number of pixels
        roi (tuple of 4 floats)
        returns (tuple of 4 floats): new ROI
        """
        # If only width or height changes, ensure we respect it by
        # adapting pixel size to be a multiple of the new size
        pxs = self.pixelSize.value

        old_roi = self.roi.value
        if old_roi != UNDEFINED_ROI and roi != UNDEFINED_ROI:
            old_size = (old_roi[2] - old_roi[0], old_roi[3] - old_roi[1])
            new_size = (roi[2] - roi[0], roi[3] - roi[1])
            if abs(old_size[0] - new_size[0]) < 1e-6:
                dim = 1
                # If dim 1 is also equal -> new pixel size will not change
            elif abs(old_size[1] - new_size[1]) < 1e-6:
                dim = 0
            else:
                dim = None

            if dim is not None:
                old_rep = self.repetition.value[dim]
                new_phy_size = old_rep * pxs * new_size[dim] / old_size[dim]
                new_rep_flt = new_phy_size / pxs
                new_rep_int = max(1, round(new_rep_flt))
                pxs *= new_rep_flt / new_rep_int
                pxs_range = self._getPixelSizeRange()
                pxs = max(pxs_range[0], min(pxs, pxs_range[1]))

        roi, rep = self._updateROIAndPixelSize(roi, pxs)
        # update repetition without going through the checks
        self.repetition._value = rep
        self.repetition.notify(rep)
        self.pixelSize._value = pxs
        self.pixelSize.notify(pxs)

        return roi

    def _setPixelSize(self, pxs):
        """
        Ensures pixel size is within the current allowed range, and updates
         ROI and repetition.
        return (float): new pixel size
        """
        # clamp
        pxs_range = self._getPixelSizeRange()
        pxs = max(pxs_range[0], min(pxs, pxs_range[1]))
        roi, rep = self._updateROIAndPixelSize(self.roi.value, pxs)

        # update roi and rep without going through the checks
        self.roi._value = roi
        self.roi.notify(roi)
        self.repetition._value = rep
        self.repetition.notify(rep)

        return pxs

    def _setRepetition(self, repetition):
        """
        Find a fitting repetition and update pixel size and ROI, using the
         current ROI making sure that the repetition is ints (pixelSize and roi
        changes are notified but the setter is not called).
        repetition (tuple of 2 ints): new repetition wanted (might be clamped)
        returns (tuple of 2 ints): new (valid) repetition
        """
        roi = self.roi.value
        # If ROI is undefined => everything is fine
        if roi == UNDEFINED_ROI:
            return repetition

        prev_rep = self.repetition.value
        epxs = self.emitter.pixelSize.value
        eshape = self.emitter.shape

        # The basic principle is that the ROI stays the same, and the pixel size
        # is modified to fit the repetition. So it's basically an indirect way
        # to change the pixel size.

        # clamp horizontal repetition to be sure it's correct
        roi_size = [roi[2] - roi[0], roi[3] - roi[1]]
        max_rep = [max(1, math.ceil(eshape[0] * roi_size[0])),
                   max(1, math.ceil(eshape[1] * roi_size[1]))]

        repetition = [min(repetition[0], max_rep[0]),
                      min(repetition[1], max_rep[1])]

        # update the pixel size according to horizontal or vertical repetition,
        # depending on what the user "asked" (changed)
        if prev_rep[0] == repetition[0]:
            # TODO: move the computations inside
            pxs = (epxs[1] * eshape[1] * roi_size[1]) / repetition[1]
        elif prev_rep[1] == repetition[1]:
            pxs = (epxs[0] * eshape[0] * roi_size[0]) / repetition[0]
        else:
            # the whole repetition changed => keep area and adapt ROI
            roi_center = [(roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2]
            area_ratio = math.sqrt(numpy.prod(prev_rep) / numpy.prod(repetition))
            rel_pxs = roi_size[0] / prev_rep[0] #, roi_size[1] / prev_rep[1])
            roi_size = [area_ratio * rel_pxs * repetition[0],
                        area_ratio * rel_pxs * repetition[1]]
            roi = [roi_center[0] - roi_size[0] / 2,
                   roi_center[1] - roi_size[1] / 2,
                   roi_center[0] + roi_size[0] / 2,
                   roi_center[1] + roi_size[1] / 2]
            pxs = self.pixelSize.value * area_ratio

        roi, rep = self._updateROIAndPixelSize(roi, pxs)
        # update roi and pixel size without going through the checks
        self.roi._value = roi
        self.roi.notify(roi)
        self.pixelSize._value = pxs
        self.pixelSize.notify(pxs)

        return rep

    def _getPixelSizeRange(self):
        """
        return (tuple of 2 floats): min and max value of the pixel size at the
          current magnification, in m.
        """
        # Two things to take care of:
        # * current pixel size of the emitter (which depends on the magnification)
        # * merge horizontal/vertical dimensions into one fits-all

        # The current emitter pixel size is the minimum size
        epxs = self.emitter.pixelSize.value
        min_pxs = max(epxs)
        shape = self.emitter.shape
        max_pxs = min(epxs[0] * shape[0], epxs[1] * shape[1])
        return (min_pxs, max_pxs)

    def estimateAcquisitionTime(self):
        try:
            rep = list(self.repetition.value)
            # Typically there is few more pixels inserted at the beginning of
            # each line for the settle time of the beam. We guesstimate by just
            # adding 1 pixel to each line
            if len(rep) >= 2 and numpy.prod(rep[1:]) > 1:
                rep[1] += 1

            # Each pixel x the exposure time (of the detector) + readout time +
            # 20% overhead
            try:
                ro_rate = self._detector.readoutRate.value
                res = self._detector.resolution.value
                readout = numpy.prod(res) / ro_rate + 0.06
            except Exception:
                readout = 0.06
            exp = self._detector.exposureTime.value
            duration = numpy.prod(rep) * (exp + readout) * 1.20
            # Add the setup time
            duration += self.SETUP_OVERHEAD

            return duration
        except Exception:
            msg = "Exception while estimating acquisition time of %s"
            logging.exception(msg, self.name.value)
            return Stream.estimateAcquisitionTime(self)

class SpectrumStream(RepetitionStream):
    """ A Spectrum stream.

    Be aware that acquisition can be very long so should not be used for live
    view. So it has no .image (for now). See StaticSpectrumStream for displaying
    a stream.
    """
    def __init__(self, name, detector, dataflow, emitter):
        RepetitionStream.__init__(self, name, detector, dataflow, emitter)
        # For SPARC: typical user wants density a bit lower than SEM
        self.pixelSize.value *= 6

class ARStream(RepetitionStream):
    """
    An angular-resolved stream, for a set of points (on the SEM).
    Be aware that acquisition can be very long so
    should not be used for live view. So it has no .image (for now).
    See StaticARStream for displaying a stream, and CameraStream for displaying
    just the current AR view.
    """
    def __init__(self, name, detector, dataflow, emitter):
        RepetitionStream.__init__(self, name, detector, dataflow, emitter)
        # For SPARC: typical user wants density much lower than SEM
        self.pixelSize.value *= 30

class StaticStream(Stream):
    """
    Stream containing one static image.
    For testing and static images.
    """
    def __init__(self, name, image):
        """
        Note: parameters are different from the base class.
        image (DataArray of shape (111)YX): static raw data.
          The metadata should contain at least MD_POS and MD_PIXEL_SIZE.
        """
        Stream.__init__(self, name, None, None, None)
        # Check it's 2D
        if len(image.shape) < 2:
            raise ValueError("Data must be 2D")
        # make it 2D by removing first dimensions (which must 1)
        if len(image.shape) > 2:
            image = img.ensure2DImage(image)

        self.onNewImage(None, image)

    def onActive(self, active):
        # don't do anything
        pass

class RGBStream(StaticStream):
    """
    A static stream which gets as input the actual RGB image
    """
    def __init__(self, name, image):
        """
        Note: parameters are different from the base class.
        image (DataArray of shape YX3): image to display.
          The metadata should contain at least MD_POS and MD_PIXEL_SIZE.
        """
        Stream.__init__(self, name, None, None, None)
        # Check it's 2D
        if not (len(image.shape) == 3 and image.shape[2] in [3, 4]):
            raise ValueError("Data must be RGB(A)")

        # TODO: use original image as raw, to allow changing the B/C/tint
        # Need to distinguish between greyscale (possible) and colour (impossible)
        self.image = VigilantAttribute(image)


class StaticSEMStream(StaticStream):
    """
    Same as a StaticStream, but considered a SEM stream
    """
    pass

class StaticBrightfieldStream(StaticStream):
    """
    Same as a StaticStream, but considered a Brightfield stream
    """
    pass

class StaticFluoStream(StaticStream):
    """Static Stream containing images obtained via epifluorescence.

    It basically knows how to show the emission/filtered wavelengths,
    and how to taint the image.
    """

    def __init__(self, name, image):
        """
        Note: parameters are different from the base class.
        image (DataArray of shape (111)YX): raw data. The metadata should
          contain at least MD_POS and MD_PIXEL_SIZE. It should also contain
          MD_IN_WL and MD_OUT_WL.
        """
        # Wavelengths
        try:
            exc_range = image.metadata[model.MD_IN_WL]
            val = numpy.mean(exc_range)
            self.excitation = model.FloatContinuous(val,
                                                    range=exc_range,
                                                    unit="m",
                                                    readonly=True)
        except KeyError:
            logging.warning("No excitation wavelength for fluorescence stream")

        try:
            em_range = image.metadata[model.MD_OUT_WL]
            val = numpy.mean(em_range)
            self.emission = model.FloatContinuous(val,
                                                  range=em_range,
                                                  unit="m",
                                                  readonly=True)

            default_tint = conversion.wave2rgb(self.emission.value)
        except KeyError:
            logging.warning("No emission wavelength for fluorescence stream")
            default_tint = (0, 255, 0) # green is most typical

        # colouration of the image
        tint = image.metadata.get(model.MD_USER_TINT, default_tint)
        self.tint = model.ListVA(tint, unit="RGB") # 3-tuple R,G,B
        self.tint.subscribe(self.onTint)

        # Do it at the end, as it forces it the update of the image
        StaticStream.__init__(self, name, image)

    def _updateImage(self): #pylint: disable=W0221
        Stream._updateImage(self, self.tint.value)

    def onTint(self, value):
        self._updateImage()


class StaticARStream(StaticStream):
    """
    A angular resolved stream for one set of data.

    There is no directly nice (=obvious) format to store AR data.
    The difficulty is that data is somehow 4 dimensions: SEM-X, SEM-Y, CCD-X,
    CCD-Y. CCD-dimensions do not correspond directly to quantities, until
    converted into angle/angle (knowing the position of the pole).
    As it's possible that positions on the SEM are relatively random, and it
    is convenient to have a simple format when only one SEM pixel is scanned,
    we've picked the following convention:
     * each CCD image is a separate DataArray
     * each CCD image contains metadata about the SEM position (MD_POS, in m)
       pole (MD_AR_POLE, in px), and acquisition time (MD_ACQ_DATE)
     * multiple CCD images are grouped together in a list
    """
    def __init__(self, name, data):
        """
        name (string)
        data (model.DataArray of shape (YX) or list of such DataArray). The
         metadata MD_POS and MD_AR_POLE should be provided
        """
        Stream.__init__(self, name, None, None, None)

        if not isinstance(data, collections.Iterable):
            data = [data] # from now it's just a list of DataArray

        # find positions of each acquisition
        # tuple of 2 floats -> DataArray: position on SEM -> data
        self._sempos = {}
        for d in data:
            try:
                self._sempos[d.metadata[MD_POS]] = img.ensure2DImage(d)
            except KeyError:
                logging.info("Skipping DataArray without known position")

        # Cached conversion of the CCD image to polar representation
        self._polar = {} # dict tuple 2 floats -> DataArray
        # TODO: automatically fill it in a background thread

        self.raw = list(self._sempos.values())

        # SEM position displayed, (None, None) == no point selected
        self.point = model.VAEnumerated((None, None),
                     choices=frozenset([(None, None)] + list(self._sempos.keys())))
        self.point.subscribe(self._onPoint)

        # The background data (typically, an acquisition without ebeam).
        # It is subtracted from the acquisition data.
        # If set to None, a simple baseline background value is subtracted.
        self.background = model.VigilantAttribute(None,
                                                  setter=self._setBackground)
        self.background.subscribe(self._onBackground)

        if self._sempos:
            # Pick one point, e.g., top-left
            bbtl = (min(x for x, y in self._sempos.keys() if x is not None),
                    min(y for x, y in self._sempos.keys() if y is not None))
            # top-left point is the closest from the bounding-box top-left
            def dis_bbtl(v):
                try:
                    return math.hypot(bbtl[0] - v[0], bbtl[1] - v[1])
                except TypeError:
                    return float("inf") # for None, None
            self.point.value = min(self._sempos.keys(), key=dis_bbtl)

    def _getPolarProjection(self, pos):
        """
        Return the polar projection of the image at the given position.
        pos (tuple of 2 floats): position (must be part of the ._sempos
        returns DataArray: the polar projection
        """
        if pos in self._polar:
            polarp = self._polar[pos]
        else:
            # Compute the polar representation
            data = self._sempos[pos]
            try:
                if numpy.prod(data.shape) > (1280 * 1080):
                    # AR conversion fails one very large images due to too much
                    # memory consumed (> 2Gb). So, use a "degraded" type that
                    # uses less memory. As the display size is small (compared
                    # to the size of the input image, it shouldn't actually
                    # affect much the output.
                    logging.info("AR image is very large %s, will convert to "
                                 "azymuthal projection in reduced precision.",
                                 data.shape)
                    dtype = numpy.float16
                else:
                    dtype = None # just let the function use the best one

                size = min(min(data.shape) * 2, 1134)

                # TODO: First compute quickly a low resolution and then
                # compute a high resolution version.
                # TODO: could use the size of the canvas that will display
                # the image to save some computation time.

                bg_data = self.background.value
                if bg_data is None:
                    # Simple version: remove the background value
                    data0 = polar.ARBackgroundSubtract(data)
                else:
                    data0 = img.Subtract(data, bg_data) # metadata from data

                # 2 x size of original image (on smallest axis) and at most
                # the size of a full-screen canvas
                polarp = polar.AngleResolved2Polar(data0, size, hole=False, dtype=dtype)
                self._polar[pos] = polarp
            except Exception:
                logging.exception("Failed to convert to azymuthal projection")
                return data # display it raw as fallback

        return polarp

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self):
        """ Recomputes the image with all the raw data available for the current
        selected point.
        """
        # check to avoid running it if there is already one running
        if not self.raw:
            return

        pos = self.point.value
        try:
            if pos == (None, None):
                self.image.value = None
            else:
                polar = self._getPolarProjection(pos)
                # update the histrogram
                # TODO: cache the histogram per image
                # FIXME: histogram should not include the black pixels outside
                # of the circle. => use a masked array?
                self._updateHistogram(polar)
                irange = self._getDisplayIRange()

                # Convert to RGB
                rgbim = img.DataArray2RGB(polar, irange)
                rgbim.flags.writeable = False
                # For polar view, no PIXEL_SIZE nor POS
                self.image.value = model.DataArray(rgbim)
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)

    def _onPoint(self, pos):
        self._updateImage()

    def _setBackground(self, data):
        """Called when the background is about to be changed"""
        if data is None:
            return

        # check it's compatible with the data
        data = img.ensure2DImage(data)
        arpole = data.metadata[model.MD_AR_POLE] # we expect the data has AR_POLE

        # TODO: allow data which is the same shape but lower binning by
        # estimating the binned image
        # Check the background data and all the raw data have the same resolution
        # TODO: how to handle if the .raw has different resolutions?
        for r in self.raw:
            if data.shape != r.shape:
                raise ValueError("Incompatible resolution of background data "
                                 "%s with the angular resolved resolution %s." %
                                 (data.shape, r.shape))
            if data.dtype != r.dtype:
                raise ValueError("Incompatible encoding of background data "
                                 "%s with the angular resolved encoding %s." %
                                 (data.dtype, r.dtype))
            try:
                if data.metadata[model.MD_BPP] != r.metadata[model.MD_BPP]:
                    raise ValueError(
                        "Incompatible format of background data "
                        "(%d bits) with the angular resolved format "
                        "(%d bits)." %
                        (data.metadata[model.MD_BPP], r.metadata[model.MD_BPP]))
            except KeyError:
                pass # no metadata, let's hope it's the same BPP

        # check the AR pole is at the same position
        for r in self.raw:
            if r.metadata[model.MD_AR_POLE] != arpole:
                logging.warning("Pole position of background data %s is "
                                "different from the data %s.",
                                arpole, r.metadata[model.MD_AR_POLE])

        return data

    def _onBackground(self, data):
        """Called when the background is changed"""
        # uncache all the polar images, and update the current image
        self._polar = {}
        self._updateImage()

class StaticSpectrumStream(StaticStream):
    """
    A Spectrum stream which displays only one static image/data.
    The main difference from the normal streams is that the data is 3D (a cube)
    The metadata should have a MD_WL_POLYNOMIAL or MD_WL_LIST
    Note that the data received should be of the (numpy) shape CYX or C11YX.
    When saving, the data will be converted to CTZYX (where TZ is 11)
    """
    def __init__(self, name, image):
        """
        name (string)
        image (model.DataArray of shape (CYX) or (C11YX)). The metadata
        MD_WL_POLYNOMIAL should be included in order to associate the C to a
        wavelength.
        """
        self._calibrated = None # just for the _updateIRange to not complain
        Stream.__init__(self, name, None, None, None)
        # Spectrum stream has in addition to normal stream:
        #  * information about the current bandwidth displayed (avg. spectrum)
        #  * coordinates of 1st point (1-point, line)
        #  * coordinates of 2nd point (line)

        if len(image.shape) == 3:
            # force 5D
            image = image[:, numpy.newaxis, numpy.newaxis, :, :]
        elif len(image.shape) != 5 or image.shape[1:3] != (1, 1):
            logging.error("Cannot handle data of shape %s", image.shape)
            raise NotImplementedError("SpectrumStream needs a cube data")

        ### this is for "average spectrum" projection
        try:
            # cached list of wavelength for each pixel pos
            self._wl_px_values = spectrum.get_wavelength_per_pixel(image)
        except (ValueError, KeyError):
            # useless polynomial => just show pixels values (ex: -50 -> +50 px)
            # TODO: try to make them always int?
            max_bw = image.shape[0] // 2
            min_bw = (max_bw - image.shape[0]) + 1
            self._wl_px_values = range(min_bw, max_bw + 1)
            assert(len(self._wl_px_values) == image.shape[0])
            unit_bw = "px"
            cwl = (max_bw + min_bw) // 2
            width = image.shape[0] // 12
        else:
            min_bw, max_bw = self._wl_px_values[0], self._wl_px_values[-1]
            unit_bw = "m"
            cwl = (max_bw + min_bw) / 2
            width = (max_bw - min_bw) / 12

        # TODO: allow to pass the calibration data as argument to avoid
        # recomputing the data just after init?
        # Spectrum efficiency compensation data: None or a DataArray (cf acq.calibration)
        self.efficiencyCompensation = model.VigilantAttribute(None)

        # low/high values of the spectrum displayed
        self.spectrumBandwidth = model.TupleContinuous(
                                    (cwl - width, cwl + width),
                                    range=((min_bw, min_bw), (max_bw, max_bw)),
                                    unit=unit_bw,
                                    cls=(int, long, float))

        # Whether the (per bandwidth) display should be split intro 3 sub-bands
        # which are applied to RGB
        self.fitToRGB = model.BooleanVA(False)

        self._irange = None

        # This attribute is used to keep track of any selected pixel within the
        # data for the display of a spectrum
        self.selected_pixel = model.TupleVA((None, None)) # int, int

        # TODO: also need the size of a point (and density?)
        # TODO: selected_line = first point, second point in pixels?
        # Should be independent from selected_pixel as it should be possible
        # to get simulatenously a spectrum along a line, and a spectrum of a
        # point (on this line)

        self.fitToRGB.subscribe(self.onFitToRGB)
        self.spectrumBandwidth.subscribe(self.onSpectrumBandwidth)
        self.efficiencyCompensation.subscribe(self._onEffComp)

        self.raw = [image] # for compatibility with other streams (like saving...)
        self._calibrated = image # the raw data after calibration

        self._updateIRange()
        self._updateHistogram()
        self._updateImage()

    # The tricky part is we need to keep the raw data as .raw for things
    # like saving the stream or updating the calibration, but all the
    # display-related methods must work on the calibrated data.
    def _updateIRange(self, data=None):
        if data is None:
            data = self._calibrated
        super(StaticSpectrumStream, self)._updateIRange()

    def _updateHistogram(self, data=None):
        if data is None:
            data = self._calibrated
        super(StaticSpectrumStream, self)._updateHistogram(data=data)

    def _get_bandwidth_in_pixel(self):
        """
        Return the current bandwidth in pixels index
        returns (2-tuple of int): low and high pixel coordinates (included)
        """
        low, high = self.spectrumBandwidth.value

        # Find the closest pixel position for the requested wavelength
        low_px = numpy.searchsorted(self._wl_px_values, low, side="left")
        low_px = min(low_px, len(self._wl_px_values) - 1) # make sure it fits
        # TODO: might need better handling to show just one pixel (in case it's
        # useful) as in almost all cases, it will end up displaying 2 pixels at
        # least
        if high == low:
            high_px = low_px
        else:
            high_px = numpy.searchsorted(self._wl_px_values, high, side="right")
            high_px = min(high_px, len(self._wl_px_values) - 1)

        logging.debug("Showing between %g -> %g nm = %d -> %d px",
                      low * 1e9, high * 1e9, low_px, high_px)
        assert low_px <= high_px
        return low_px, high_px

    def _updateImageAverage(self, data):
        if self.auto_bc.value:
            # The histogram might be slightly old, but not too much
            irange = img.findOptimalRange(self.histogram._full_hist,
                                          self.histogram._edges,
                                          self.auto_bc_outliers.value / 100)

            # Also update the intensityRanges if auto BC
            edges = self.histogram._edges
            rrange = [(v - edges[0]) / (edges[1] - edges[0]) for v in irange]
            self.intensityRange.value = tuple(rrange)
        else:
            # just convert from the user-defined (as ratio) to actual values
            rrange = sorted(self.intensityRange.value)
            edges = self.histogram._edges
            irange = [edges[0] + (edges[1] - edges[0]) * v for v in rrange]

        # pick only the data inside the bandwidth
        spec_range = self._get_bandwidth_in_pixel()
        logging.debug("Spectrum range picked: %s px", spec_range)

        if not self.fitToRGB.value:
            # TODO: use better intermediary type if possible?, cf semcomedi
            av_data = numpy.mean(data[spec_range[0]:spec_range[1] + 1], axis=0)
            av_data = img.ensure2DImage(av_data)
            rgbim = img.DataArray2RGB(av_data, irange)
        else:
            # Note: For now this method uses three independant bands. To give
            # a better sense of continum, and be closer to reality when using
            # the visible light's band, we should take a weighted average of the
            # whole spectrum for each band.

            # divide the range into 3 sub-ranges of almost the same length
            len_rng = spec_range[1] - spec_range[0] + 1
            rrange = [spec_range[0], int(round(spec_range[0] + len_rng / 3)) - 1]
            grange = [rrange[1] + 1, int(round(spec_range[0] + 2 * len_rng / 3)) - 1]
            brange = [grange[1] + 1, spec_range[1]]
            # ensure each range contains at least one pixel
            rrange[1] = max(rrange)
            grange[1] = max(grange)
            brange[1] = max(brange)

            # FIXME: unoptimized, as each channel is duplicated 3 times, and discarded
            av_data = numpy.mean(data[rrange[0]:rrange[1] + 1], axis=0)
            av_data = img.ensure2DImage(av_data)
            rgbim = img.DataArray2RGB(av_data, irange)
            av_data = numpy.mean(data[grange[0]:grange[1] + 1], axis=0)
            av_data = img.ensure2DImage(av_data)
            gim = img.DataArray2RGB(av_data, irange)
            rgbim[:, :, 1] = gim[:, :, 0]
            av_data = numpy.mean(data[brange[0]:brange[1] + 1], axis=0)
            av_data = img.ensure2DImage(av_data)
            bim = img.DataArray2RGB(av_data, irange)
            rgbim[:, :, 2] = bim[:, :, 0]

        rgbim.flags.writeable = False
        self.image.value = model.DataArray(rgbim, self._find_metadata(data))

    def get_spectrum_range(self):
        """
        Return the wavelength for each pixel of a (complete) spectrum
        returns (list of numbers or None): one wavelength per spectrum pixel.
          Values are in meters, unless the spectrum cannot be determined, in
          which case integers representing pixels index is returned.
          If no data is available, None is returned.
        """
        # TODO return unit too? (i.e., m or px)
        data = self._calibrated

        try:
            return spectrum.get_wavelength_per_pixel(data)
        except (ValueError, KeyError):
            # useless polynomial => just show pixels values (ex: -50 -> +50 px)
            max_bw = data.shape[0] // 2
            min_bw = (max_bw - data.shape[0]) + 1
            return range(min_bw, max_bw + 1)

    def get_pixel_spectrum(self):
        """ Return the spectrum belonging to the selected pixel or None if no
        spectrum is selected.
        """
        if self.selected_pixel.value != (None, None):
            x, y = self.selected_pixel.value
            return self._calibrated[:, 0, 0, y, x]
        return None

    # TODO: have an "area=None" argument which allows to specify the 2D region
    # within which the spectrum should be computed
    # TODO: should it also return the wavelength values? Or maybe another method
    # can do it?
    def getMeanSpectrum(self):
        """
        Compute the global spectrum of the data as an average over all the pixels
        returns (numpy.ndarray of float): average intensity for each wavelength
         You need to use the metadata of the raw data to find out what is the
         wavelength for each pixel, but the range of wavelengthBandwidth is
         the same as the range of this spectrum.
        """
        data = self._calibrated
        # flatten all but the C dimension, for the average
        data = data.reshape((data.shape[0], numpy.prod(data.shape[1:])))
        av_data = numpy.mean(data, axis=1)

        return av_data

    @limit_invocation(0.1) # Max 10 Hz
    def _updateImage(self):
        """ Recomputes the image with all the raw data available
          Note: for spectrum-based data, it mostly computes a projection of the
          3D data to a 2D array.
        """
        try:
            data = self._calibrated
            if data is None: # can happen during __init__
                return
            self._updateImageAverage(data)
        except Exception:
            logging.exception("Updating %s image", self.__class__.__name__)


    def _onEffComp(self, calib_data):
        """
        called when the efficiency compensation is changed
        """
        data = self.raw[0]

        # We don't have problems of rerunning this when the data is updated,
        # as the data is static.
        if calib_data is None:
            self._calibrated = data
        elif not (set(data.metadata.keys()) & {model.MD_WL_LIST, model.MD_WL_POLYNOMIAL}):
            # don't try if there is no wavelength info (in px)
            self._calibrated = data
        else:
            try:
                self._calibrated = calibration.compensate_spectrum_efficiency(
                                                                    data,
                                                                    calib_data)
            except Exception:
                logging.exception(
                    "Failed to apply the spectrum efficiency compensation")
                self._calibrated = data

        # histogram will change as the pixel intensity is different
        self._updateIRange()
        self._updateHistogram()

        self._updateImage()
        # TODO: if the 0D spectrum is used, it should be updated too, but
        # there is no explicit way to do it, so instead, pretend the pixel has
        # moved. It could be solved by using dataflows.
        if self.selected_pixel.value != (None, None):
            self.selected_pixel.notify(self.selected_pixel.value)

    def onFitToRGB(self, value):
        """
        called when fitToRGB is changed
        """
        self._updateImage()

    def onSpectrumBandwidth(self, value):
        """
        called when spectrumBandwidth is changed
        """
        self._updateImage()

class MultipleDetectorStream(Stream):
    """
    Abstract class for all specialized streams which are actually a combination
    of multiple streams acquired simultaneously. The main difference from a
    normal stream is the init arguments are Streams, and .raw is composed of all
    the .raw from the sub-streams.
    """
    def __init__(self, name, streams):
        """
        streams (list of Streams): all the sub-streams that are used to
            decompose
        """
        # don't call the init of Stream, or it will override .raw
        self.name = model.StringVA(name)
        self._streams = streams

    @property
    def raw(self):
        # build the .raw from all the substreams
        r = []
        for s in self._streams:
            r.extend(s.raw)
        return r

class SEMCCDMDStream(MultipleDetectorStream):
    """
    Abstract class for multiple detector Stream made of SEM + CCD.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    It provides to subclasses two ways to acquire the data:
     * software synchronised = the acquisition code takes care of moving the
       SEM spot and starts a new CCD acquisition at each spot. A bit more
       overhead but very reliable, so use for long dwell times.
     * driver synchronised = the SEM is programmed to acquire the whole grid and
       automatically synchronises the CCD. As the dwell time is constant, it
       must be bigger than the worst time for CCD acquisition. Less overhead,
       so good for short dwell times.
    TODO: in software synchronisation, we can easily do our own fuzzing.
    """
    __metaclass__ = ABCMeta
    def __init__(self, name, sem_stream, ccd_stream):
        MultipleDetectorStream.__init__(self, name, [sem_stream, ccd_stream])

        self._sem_stream = sem_stream
        self._ccd_stream = ccd_stream

        assert sem_stream._emitter == ccd_stream._emitter
        self._emitter = sem_stream._emitter
        # probably secondary electron detector
        self._semd = self._sem_stream._detector
        self._semd_df = self._sem_stream._dataflow
        self._ccd = self._ccd_stream._detector # CCD
        self._ccd_df = self._ccd_stream._dataflow

        # For the acquisition
        self._acq_lock = threading.Lock()
        self._acq_state = RUNNING
        self._acq_sem_complete = threading.Event()
        self._acq_ccd_complete = threading.Event()
        self._acq_thread = None # thread
        self._acq_ccd_tot = 0 # number of CCD acquisitions to do
        self._acq_ccd_n = 0 # number of CCD acquisitions so far
        self._acq_start = 0 # time of acquisition beginning
        self._sem_data = None
        self._ccd_data = None

        # For the drift correction
        self._dc_estimator = None
        self._current_future = None

        self.should_update = model.BooleanVA(False)
        self.is_active = model.BooleanVA(False)

    def estimateAcquisitionTime(self):
        # Time required without drift correction
        acq_time = self._ccd_stream.estimateAcquisitionTime()

        if self._sem_stream.dcRegion.value == UNDEFINED_ROI:
            return acq_time

        # Estimate time spent in scanning the anchor region
        exp = self._ccd.exposureTime.value #s
        ccd_size = self._ccd.resolution.value
        readout = numpy.prod(ccd_size) / self._ccd.readoutRate.value
        dt = exp + readout

        dc_estimator = acq_drift.AnchoredEstimator(self._emitter,
                             self._semd,
                             self._sem_stream.dcRegion.value,
                             self._sem_stream.dcDwellTime.value)
        period = dc_estimator.estimateCorrectionPeriod(
                                           self._sem_stream.dcPeriod.value,
                                           dt,
                                           self._ccd_stream.repetition.value)
        # number of times the anchor will be acquired
        npixels = numpy.prod(self._ccd_stream.repetition.value)
        n_anchor = 1 + npixels // period.next()
        anchor_time = n_anchor * dc_estimator.estimateAcquisitionTime()

        total_time = acq_time + anchor_time
        logging.debug("Estimated overhead time for drift correction: %g s / %g s",
                      anchor_time, total_time)
        return total_time

    def acquire(self):
        # TODO: if already acquiring, queue the Future for later acquisition
        if self._current_future != None and not self._current_future.done():
            raise IOError("Cannot do multiple acquisitions simultaneously")

        if self._acq_thread and self._acq_thread.isAlive():
            logging.debug("Waiting for previous acquisition to fully finish")
            self._acq_thread.join(10)
            if self._acq_thread.isAlive():
                logging.error("Previous acquisition not ending")

        # At this point dcRegion and dcDwellTime must have been set
        if self._sem_stream.dcRegion.value != UNDEFINED_ROI:
            self._dc_estimator = acq_drift.AnchoredEstimator(self._emitter,
                                         self._semd,
                                         self._sem_stream.dcRegion.value,
                                         self._sem_stream.dcDwellTime.value)
        else:
            self._dc_estimator = None


        est_start = time.time() + 0.1
        f = model.ProgressiveFuture(start=est_start,
                                    end=est_start + self.estimateAcquisitionTime())
        self._current_future = f
        self._acq_state = RUNNING # TODO: move to per acquisition

        # Pick the right acquisition method
        # DEBUG: for now driver-synchronised is too unstable and slow (due to
        # not able to wait for the CCD to be done). So we always use the
        # software-synchronised acquisition.
        if False and self._ccd.exposureTime.value <= 0.1:
            # short dwell time => use driver synchronisation
            runAcquisition = self._dsRunAcquisition
            f.task_canceller = self._dsCancelAcquisition
        else:
            # long dwell time => use software synchronisation
            runAcquisition = self._ssRunAcquisition
            f.task_canceller = self._ssCancelAcquisition

        # run task in separate thread
        self._acq_thread = threading.Thread(target=_futures.executeTask,
                              name="SEM/CCD acquisition",
                              args=(f, runAcquisition, f))
        self._acq_thread.start()
        return f

    @abstractmethod
    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        called at the end of an entire acquisition
        sem_data (DataArray): the SEM data
        ccd_data (list of DataArray): the CCD data (ordered, with X changing
          fast, then Y slow)
        """
        pass

    def _updateProgress(self, future, start, ratio):
        """
        update end time of future
        future (ProgressiveFuture): future to update
        start (float): start time
        ratio (0<=float<=1): progress ratio
        """
        now = time.time()
        tot_time = (now - start) / ratio
        # add some overhead for the end of the acquisition
        future.set_end_time(start + tot_time + 0.1)

    def _ssCancelAcquisition(self, future):
        with self._acq_lock:
            if self._acq_state == FINISHED:
                return False # too late
            self._acq_state = CANCELLED

        msg = ("Cancelling acquisition of components %s and %s")
        logging.debug(msg, self._semd.name, self._ccd.name)

        # Do it in any case, to be sure
        self._semd_df.unsubscribe(self._ssOnSEMImage)
        self._ccd_df.unsubscribe(self._ssOnCCDImage)
        self._ccd_df.synchronizedOn(None)
        # set the events, so the acq thread doesn't wait for them
        self._acq_ccd_complete.set()
        self._acq_sem_complete.set()
        return True

    def _ssAdjustHardwareSettings(self):
        """
        Read the SEM and AR stream settings and adapt the SEM scanner
        accordingly.
        return (float): estimated time for a whole CCD image
        """
        # Set SEM to spot mode, without caring about actual position (set later)
        self._emitter.scale.value = (1, 1) # min, to avoid limits on translation
        self._emitter.resolution.value = (1, 1)

        # Dwell Time: a "little bit" more than the exposure time
        exp = self._ccd.exposureTime.value #s
        ccd_size = self._ccd.resolution.value

        # Dwell time as long as possible, but better be slightly shorter than
        # CCD to be sure it is not slowing thing down.
        readout = numpy.prod(ccd_size) / self._ccd.readoutRate.value
        rng = self._emitter.dwellTime.range
        self._emitter.dwellTime.value = sorted(rng + (exp + readout,))[1] # clip

        return exp + readout

    def _getSpotPositions(self):
        """
        Compute the positions of the e-beam for each point in the ROI
        return (numpy ndarray of floats of shape (X,Y,2)): each value is for a
          given X/Y in the repetition grid -> 2 floats corresponding to the
          translation.
        """
        repetition = tuple(self._ccd_stream.repetition.value)
        roi = self._ccd_stream.roi.value
        width = (roi[2] - roi[0], roi[3] - roi[1])

        # Take into account the "border" around each pixel
        pxs = (width[0] / repetition[0], width[1] / repetition[1])
        lim = (roi[0] + pxs[0] / 2, roi[1] + pxs[1] / 2,
               roi[2] - pxs[0] / 2, roi[3] - pxs[1] / 2)

        shape = self._emitter.shape
        # convert into SEM translation coordinates: distance in px from center
        # (situated at 0.5, 0.5), can be floats
        lim_sem = (shape[0] * (lim[0] - 0.5), shape[1] * (lim[1] - 0.5),
                   shape[0] * (lim[2] - 0.5), shape[1] * (lim[3] - 0.5))
        logging.debug("Generating points in the SEM area %s", lim_sem)

        pos = numpy.empty(repetition + (2,), dtype=numpy.float)
        posx = pos[:, :, 0].swapaxes(0, 1) # just a view to have X as last dim
        posx[:, :] = numpy.linspace(lim_sem[0], lim_sem[2], repetition[0])
        # fill the X dimension
        pos[:, :, 1] = numpy.linspace(lim_sem[1], lim_sem[3], repetition[1])
        return pos

    def _ssRunAcquisition(self, future):
        """
        Acquires SEM/CCD images via software synchronisation.
        Warning: can be quite memory consuming if the grid is big
        returns (list of DataArray): all the data acquired
        raises:
          CancelledError() if cancelled
          Exceptions if error
        """
        # TODO: handle better very large grid acquisition (than memory oops)
        try:
            ccd_time = self._ssAdjustHardwareSettings()
            dwell_time = self._emitter.dwellTime.value
            spot_pos = self._getSpotPositions()
            logging.debug("Generating %s spots for %g (=%g) s", spot_pos.shape[:2], ccd_time, dwell_time)
            rep = self._ccd_stream.repetition.value
            roi = self._ccd_stream.roi.value
            self._sem_data = []
            self._ccd_data = None
            ccd_buf = []
            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            logging.debug("Starting CCD acquisition with components %s and %s",
                          self._semd.name, self._ccd.name)

            # We need to use synchronisation event because without it, either we
            # use .get() but it's not possible to cancel the acquisition, or we
            # subscribe/unsubscribe for each image, but the overhead is high.
            trigger = self._ccd.softwareTrigger
            self._ccd_df.synchronizedOn(trigger)
            self._ccd_df.subscribe(self._ssOnCCDImage)

            tot_num = numpy.prod(rep)
            n = 0

            # Translate dc_period to a number of pixels
            pxs_dc_period = self._dc_estimator.estimateCorrectionPeriod(
                                    self._sem_stream.dcPeriod.value,
                                    ccd_time,
                                    rep)
            cur_dc_period = pxs_dc_period.next()

            # First acquisition of anchor area
            self._dc_estimator.acquire()

            start_time = time.time()
            for i in numpy.ndindex(*rep[::-1]): # last dim (X) iterates first
                self._emitter.translation.value = (spot_pos[i[::-1]][0],
                                                   spot_pos[i[::-1]][1])
                logging.debug("E-beam spot after drift correction: %s",
                              self._emitter.translation.value)

                self._acq_sem_complete.clear()
                self._acq_ccd_complete.clear()
                self._semd_df.subscribe(self._ssOnSEMImage)
                time.sleep(0) # give more chances spot has been already processed
                start = time.time()
                trigger.notify()

                if not self._acq_ccd_complete.wait(ccd_time * 2 + 5):
                    raise TimeoutError("Acquisition of CCD for pixel %s timed out" % (i,))
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                dur = time.time() - start
                if dur < ccd_time:
                    logging.warning("CCD acquisition took less that %g s: %g s",
                                    ccd_time, dur)

                # Normally, the SEM acquisition has already completed
                if not self._acq_sem_complete.wait(dwell_time * 1.5 + 1):
                    raise TimeoutError("Acquisition of SEM pixel %s timed out" % (i,))
                # TODO: we don't really need to stop it, we could have a small
                # dwell time, move the ebeam to the new position, and as soon as
                # we get next acquisition we can expect the spot has moved. The
                # advantage would be to avoid setting the ebeam back to resting
                # position, and reduce overhead of stopping/starting.
                self._semd_df.unsubscribe(self._ssOnSEMImage)

                if self._acq_state == CANCELLED:
                    raise CancelledError()

                # MD_POS default to the center of the stage, but it needs to be
                # the position of the e-beam
                ccd_data = self._ccd_data
                ccd_data.metadata[MD_POS] = self._sem_data[-1].metadata[MD_POS]
                ccd_data.metadata[MD_DESCRIPTION] = self._ccd_stream.name.value
                ccd_buf.append(ccd_data)

                n += 1
                # Trick: we don't count the first frame because it's often
                # much slower and so messes up the estimation
                if n == 1:
                    start_time = time.time()
                else:
                    self._updateProgress(future, start_time, (n - 1) / (tot_num - 1))

                # Check if it is time for drift correction
                if self._dc_estimator is not None and n >= cur_dc_period:
                    cur_dc_period = pxs_dc_period.next()

                    # Cannot cancel during this time, but hopefully it's short
                    # Acquisition of anchor area
                    self._dc_estimator.acquire()

                    if self._acq_state == CANCELLED:
                        raise CancelledError()

                    # Estimate drift and update next positions
                    drift = self._dc_estimator.estimate()
                    spot_pos[:, :, 0] -= drift[0]
                    spot_pos[:, :, 1] -= drift[1]

                    n = 0

            self._ccd_df.unsubscribe(self._ssOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            with self._acq_lock:
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                self._acq_state = FINISHED

            sem_one = self._assembleSEMData(rep, roi, self._sem_data) # shape is (Y, X)
            # explicitly add names to make sure they are different
            sem_one.metadata[MD_DESCRIPTION] = self._sem_stream.name.value
            self._onSEMCCDData(sem_one, ccd_buf)
        except Exception as exp:
            if not isinstance(exp, CancelledError):
                logging.exception("Software sync acquisition of SEM/CCD failed")

            # make sure it's all stopped
            self._semd_df.unsubscribe(self._ssOnSEMImage)
            self._ccd_df.unsubscribe(self._ssOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            if not isinstance(exp, CancelledError) and self._acq_state == CANCELLED:
                logging.warning("Converting exception to cancellation")
                raise CancelledError()
            raise
        else:
            return self.raw
        finally:
            del self._sem_data # regain a bit of memory

    def _ssOnSEMImage(self, df, data):
        logging.debug("SEM data received")
        # Do not stop the acquisition, as it ensures the e-beam is at the right place
        if not self._acq_sem_complete.is_set():
            # only use the first data per pixel
            self._sem_data.append(data)
            self._acq_sem_complete.set()

    def _ssOnCCDImage(self, df, data):
        logging.debug("CCD data received")
        self._ccd_data = data
        self._acq_ccd_complete.set()

    def _assembleSEMData(self, rep, roi, data_list):
        """
        Take all the data received from the SEM and assemble it in a 2D image.
        The result goes into .raw.

        rep (tuple of 2 0<ints): X/Y repetition
        roi (tupel of 3 0<floats<=1): region of interest in logical coordinates
        data_list (list of M DataArray of shape (1, 1)): all the data received,
        with X variating first, then Y.
        """
        assert len(data_list) > 0

        # start with the metadata from the first point
        md = dict(data_list[0].metadata)

        # Compute center of area, from average of centered acquisitions
        idx_center = rep[0] // 2
        if idx_center * 2 == rep[0]: # even number => average
            posx = (data_list[idx_center - 1].metadata[MD_POS][0] +
                    data_list[idx_center].metadata[MD_POS][0]) / 2
        else: # odd number => center
            posx = data_list[idx_center].metadata[MD_POS][0]
        idx_center = rep[1] // 2
        if idx_center * 2 == rep[1]: # even number => average
            posy = (data_list[rep[0] * (idx_center - 1)].metadata[MD_POS][1] +
                    data_list[rep[0] * idx_center].metadata[MD_POS][1]) / 2
        else: # odd number => center
            posy = data_list[rep[0] * idx_center].metadata[MD_POS][1]

        # Pixel size is the size of field of view divided by the repetition
        sem_pxs = self._emitter.pixelSize.value
        sem_shape = self._emitter.shape[:2]
        width = (roi[2] - roi[0], roi[3] - roi[1])
        fov = (width[0] * sem_shape[0] * sem_pxs[0],
               width[1] * sem_shape[1] * sem_pxs[1])
        pxs = (fov[0] / rep[0], fov[1] / rep[1])

        md.update({MD_POS: (posx, posy),
                   MD_PIXEL_SIZE: pxs})

        # concatenate data into one big array of (number of pixels,1)
        sem_data = numpy.concatenate(data_list)
        # reshape to (Y, X)
        sem_data.shape = rep[::-1]
        sem_data = model.DataArray(sem_data, metadata=md)
        return sem_data

    def _dsCancelAcquisition(self, future):
        with self._acq_lock:
            if self._acq_state == FINISHED:
                return False # too late
            self._acq_state = CANCELLED
        msg = ("Cancelling acquisition of components %s and %s")
        logging.debug(msg, self._semd.name, self._ccd.name)

        self._semd_df.unsubscribe(self._dsOnSEMImage)
        self._ccd_df.unsubscribe(self._dsOnCCDImage)
        self._ccd_df.synchronizedOn(None)
        # set the event, so the acq thread doesn't wait for them
        self._acq_ccd_complete.set()
        self._acq_sem_complete.set()
        return True

    def _dsAdjustHardwareSettings(self):
        """
        Read the SEM and CCD stream settings and adapt the scanner accordingly.
        """
        # ROI
        rep = list(self._ccd_stream.repetition.value)
        roi = self._ccd_stream.roi.value
        center = ((roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2)
        width = (roi[2] - roi[0], roi[3] - roi[1])

        shape = self._emitter.shape
        # translation is distance from center (situated at 0.5, 0.5), can be floats
        trans = (shape[0] * (center[0] - 0.5), shape[1] * (center[1] - 0.5))
        # scale is how big is a pixel compared to the minimum pixel size (1/shape)
        scale = (max(1, (shape[0] * width[0]) / rep[0]),
                 max(1, (shape[1] * width[1]) / rep[1]))

        logging.debug("Setting SEM ROI to resolution = %s, translation = %s, and "
                      "scale = %s", rep, trans, scale)

        # always in this order
        self._emitter.scale.value = scale
        self._emitter.resolution.value = rep
        self._emitter.translation.value = trans

        # Dwell Time: a "little bit" more than the exposure time
        exp = self._ccd.exposureTime.value #s
        ccd_size = self._ccd.resolution.value

        # "Magical" formula to get a long enough dwell time. It has to be as
        # long as the maximum CCD acquisition => needs a bit of margin.
        # Works with PVCam and Andorcam2, but not fool proof at all!
        readout = numpy.prod(ccd_size) / self._ccd.readoutRate.value + 0.01
        # 50ms to account for the overhead and extra image acquisition
        dt = (exp + readout) * 1.3 + 0.05
        rng = self._emitter.dwellTime.range
        self._emitter.dwellTime.value = sorted(rng + (dt,))[1] # clip

        # Take into account settle time
        if len(rep) == 2 and rep[1] > 1:
            rep[1] += 1
        tot_time = (self._emitter.dwellTime.value + 0.01) * numpy.prod(rep)

        return tot_time

    def _dsRunAcquisition(self, future):
        """
        Wait until the acquisition is complete, to update the data and stop the
        updates.
        To be run as a separate thread, after the SEM data has arrived.
        return (list of DataArray): all the data acquired
        raises:
          CancelledError() if cancelled
          Exceptions if error
        """
        try:
            # reset everything (ready for one acquisition)
            tot_time = self._dsAdjustHardwareSettings()
            rep = self._ccd_stream.repetition.value
            self._acq_ccd_tot = numpy.prod(rep)
            self._acq_ccd_n = 0
            self._acq_ccd_buf = []
            self._sem_data = None # One DataArray
            self._acq_ccd_complete.clear()
            self._acq_sem_complete.clear()

            self._ccd_df.synchronizedOn(self._emitter.newPosition)
            self._ccd_df.subscribe(self._dsOnCCDImage)
            self._acq_start = time.time()
            self._semd_df.subscribe(self._dsOnSEMImage)

            # Wait until it's all done
            if not self._acq_ccd_complete.wait(tot_time * 1.5 + 1):
                raise TimeoutError("Acquisition of SEM/CCD timed out")
            if not self._acq_sem_complete.wait(self._emitter.dwellTime.value + 1):
                raise TimeoutError("Acquisition of SEM/CCD timed out")
            self._ccd_df.synchronizedOn(None)

            with self._acq_lock:
                if self._acq_state == CANCELLED:
                    raise CancelledError()
                self._acq_state = FINISHED

            # actually only useful for AR acquisition
            sem_md = self._sem_data.metadata
            pos = sem_md[MD_POS]
            pxs = sem_md[MD_PIXEL_SIZE]
            self._dsUpdateCCDMetadata(self._acq_ccd_buf, rep, pos, pxs)

            # explicitly add names to make sure they are different
            ccd_stream_name = self._ccd_stream.name.value
            for d in self._acq_ccd_buf:
                d.metadata[MD_DESCRIPTION] = ccd_stream_name
            sem_md[MD_DESCRIPTION] = self._sem_stream.name.value
            self._onSEMCCDData(self._sem_data, self._acq_ccd_buf)
        except Exception as exp:
            if not isinstance(exp, CancelledError):
                logging.exception("Driver sync acquisition of SEM/CCD failed")

            # make sure it's all stopped
            self._semd_df.unsubscribe(self._dsOnSEMImage)
            self._ccd_df.unsubscribe(self._dsOnCCDImage)
            self._ccd_df.synchronizedOn(None)

            self._ccd_stream.raw = []
            self._sem_stream.raw = []
            if not isinstance(exp, CancelledError) and self._acq_state == CANCELLED:
                logging.warning("Converting exception to cancellation")
                raise CancelledError()
            raise
        else:
            return self.raw
        finally:
            del self._acq_ccd_buf # regain a bit of memory

    def _dsUpdateCCDMetadata(self, das, rep, pos, pxs):
        """
        Updates the MD_POS metadata of the CCD data (=spot position)
        das (list of DataArrays): X*Y data, ordered in X, then Y acquire
        rep (tuple of 2 int): dimension of X and Y
        pos (tuple of 2 float): center
        pxs (tuple of 2 float): physical distance between spots
        returns nothing, just updates das
        """
        pos0 = (pos[0] - (pxs[0] * (rep[0] - 1) / 2),
                pos[1] - (pxs[1] * (rep[1] - 1) / 2))
        for idx, d in zip(numpy.ndindex(*rep[::-1]), das):
            # rep is reversed as numpy scans last dim first
            d.metadata[MD_POS] = (pos0[0] + idx[1] * pxs[0],
                                  pos0[1] + idx[0] * pxs[1])

    def _dsOnCCDImage(self, df, data):
        # the data array subscribers must be fast, so the real processing
        # takes place later
        self._acq_ccd_buf.append(data)
        # TODO: update the estimated time based on how long it takes per pixel
        # in reality

        self._acq_ccd_n += 1
        ratio = self._acq_ccd_n / self._acq_ccd_tot
        self._updateProgress(self._current_future, self._acq_start, ratio)
        if self._acq_ccd_n >= self._acq_ccd_tot:
            # unsubscribe to stop immediately
            df.unsubscribe(self._dsOnCCDImage)
            self._acq_ccd_complete.set()

    def _dsOnSEMImage(self, df, data):
        # unsubscribe to stop immediately
        df.unsubscribe(self._dsOnSEMImage)
        self._sem_data = data
        self._acq_sem_complete.set()

class SEMSpectrumMDStream(SEMCCDMDStream):
    """
    Multiple detector Stream made of SEM + Spectrum.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    """

    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        cf SEMCCDMDStream._onSEMCCDData()
        """
        assert ccd_data[0].shape[-2] == 1 # should be a spectra (Y == 1)
        repetition = sem_data.shape[-1:-3:-1] # 1,1,1,Y,X -> X, Y

        # assemble all the CCD data into one
        spec_data = self._assembleSpecData(ccd_data, repetition)
        md_sem = sem_data.metadata
        try:
            spec_data.metadata[MD_PIXEL_SIZE] = md_sem[MD_PIXEL_SIZE]
            spec_data.metadata[MD_POS] = md_sem[MD_POS]
        except KeyError:
            logging.warning("Metadata missing from the SEM data")

        # save the new data
        self._ccd_stream.raw = [spec_data]
        self._sem_stream.raw = [sem_data]

    def _assembleSpecData(self, data_list, repetition):
        """
        Take all the data received from the spectrometer and assemble it in a
        cube.

        data_list (list of M DataArray of shape (1, N)): all the data received
        repetition (list of 2 int): X,Y shape of the high dimensions of the cube
         so that X * Y = M
        return (DataArray)
        """
        assert len(data_list) > 0

        # each element of acq_spect_buf has a shape of (1, N)
        # reshape to (N, 1)
        for e in data_list:
            e.shape = e.shape[::-1]
        # concatenate into one big array of (N, number of pixels)
        spec_data = numpy.concatenate(data_list, axis=1)
        # reshape to (C, 1, 1, Y, X) (as C must be the 5th dimension)
        spec_res = data_list[0].shape[0]
        spec_data.shape = (spec_res, 1, 1, repetition[1], repetition[0])

        # copy the metadata from the first point and add the ones from metadata
        md = data_list[0].metadata
        return model.DataArray(spec_data, metadata=md)


class SEMARMDStream(SEMCCDMDStream):
    """
    Multiple detector Stream made of SEM + AR.
    It handles acquisition, but not rendering (so .image always returns an empty
    image).
    """

    def _onSEMCCDData(self, sem_data, ccd_data):
        """
        cf SEMCCDMDStream._onSEMCCDData()
        """
        # Not much to do: just save everything as is

        # MD_AR_POLE is set automatically, copied from the lens property.
        # In theory it's dependant on MD_POS, but so slightly that we don't need
        # to correct it.
        self._ccd_stream.raw = ccd_data
        self._sem_stream.raw = [sem_data]

# On the SPARC, it's possible that both the AR and Spectrum are acquired in the
# same acquisition, but it doesn't make much sense to acquire them
# simultaneously because the two optical detectors need the same light, and a
# mirror is used to select which path is taken. In addition, the AR stream will
# typically have a lower repetition (even if it has same ROI). So it's easier
# and faster to acquire them sequentially. The only trick is that if drift
# correction is used, the same correction must be used for the entire
# acquisition.

# Generic cross-cut types
# All the stream types related to optical
OPTICAL_STREAMS = (CameraStream,
                   StaticFluoStream,
                   StaticBrightfieldStream)

# All the stream types related to electron microscope
EM_STREAMS = (SEMStream,
              StaticSEMStream)

SPECTRUM_STREAMS = (SpectrumStream,
                    StaticSpectrumStream,
                    SEMSpectrumMDStream)

AR_STREAMS = (ARStream,
              StaticARStream,
              SEMARMDStream)

# TODO: make it like a VA, so that it's possible to know when it changes
class StreamTree(object):
    """ Object which contains a set of streams, and how they are merged to
    appear as one image. It's a tree which has one stream per leaf and one merge
    operation per node. => recursive structure (= A tree is just a node with
    a merge method and a list of subnodes, either streamtree as well, or stream)
    """

    def __init__(self, operator=None, streams=None, **kwargs):
        """
        :param operator: (callable) a function that takes a list of
            RGB DataArrays in the same order as the streams are given and the
            additional arguments and returns one DataArray.
            By default operator is an average function.
        :param streams: (list of Streams or StreamTree): a list of streams, or
            StreamTrees.
            If a StreamTree is provided, its outlook is first computed and then
            passed as an RGB DataArray.
        :param kwargs: any argument to be given to the operator function
        """
        self.operator = operator or img.Average

        streams = streams or []
        assert(isinstance(streams, list))

        self.streams = []
        self.should_update = model.BooleanVA(False)
        self.kwargs = kwargs

        for s in streams:
            self.add_stream(s)

    def __str__(self):
        return "[" + ", ".join([str(s) for s in self.streams]) + "]"

    def __len__(self):
        acc = 0

        for s in self.streams:
            if isinstance(s, Stream):
                acc += 1
            elif isinstance(s, StreamTree):
                acc += len(s)

        return acc

    def __getitem__(self, index):
        """ Return the Stream of StreamTree using index reference val[i] """
        return self.streams[index]

    def add_stream(self, stream):
        if isinstance(stream, (Stream, StreamTree)):
            self.streams.append(stream)
            if hasattr(stream, 'should_update'):
                stream.should_update.subscribe(self.stream_update_changed,
                                               init=True)
            # print "stream added %s" % stream.should_update.value
        else:
            msg = "Illegal type %s found in add_stream!" % type(stream)
            raise ValueError(msg)

    def remove_stream(self, stream):
        if hasattr(stream, 'should_update'):
            stream.should_update.unsubscribe(self.stream_update_changed)
        self.streams.remove(stream)
        self.stream_update_changed()

    def stream_update_changed(self, should_update=None):
        """ This method is called when one of the streams' should_update
        vigilant attribute changes.
        """
        # At least one stream is live, so we 'should update'
        for s in self.streams:
            if hasattr(s, "should_update") and s.should_update.value:
                self.should_update.value = True
                break
        else:
            self.should_update.value = False

    def getStreams(self):
        """
        Return the set of streams used to compose the picture. In other words,
        the leaves of the tree.
        """
        leaves = set()
        for s in self.streams:
            if isinstance(s, Stream):
                leaves.add(s)
            elif isinstance(s, StreamTree):
                leaves |= s.getStreams()

        return leaves

    def getImage(self, rect, mpp):
        """
        Returns an image composed of all the current stream images.
        Precisely, it returns the output of a call to operator.
        rect (2-tuple of 2-tuple of float): top-left and bottom-right points in
          world position (m) of the area to draw
        mpp (0<float): density (meter/pixel) of the image to compute
        """
        # TODO: probably not so useful function, need to see what canvas
        #  it will likely need as argument a wx.Bitmap, and view rectangle
        #  that will define where to save the result

        # TODO: cache with the given rect and mpp and last update time of each
        # image

        # create the arguments list for operator
        images = []
        for s in self.streams:
            if isinstance(s, Stream):
                images.append(s.image.value)
            elif isinstance(s, StreamTree):
                images.append(s.getImage(rect, mpp))


        return self.operator(images, rect, mpp, **self.kwargs)

    def getImages(self):
        """
        return a list of all the .image (which are not None)
        """
        images = []
        for s in self.streams:
            if isinstance(s, StreamTree):
                images.extend(s.getImages())
            elif isinstance(s, Stream):
                if hasattr(s, "image"):
                    im = s.image.value
                    if im is not None:
                        images.append(im)

        return images

    def getRawImages(self):
        """
        Returns a list of all the raw images used to create the final image
        """
        # TODO not sure if a list is enough, we might need to return more
        # information about how the image was built (operator, args...)
        lraw = []
        for s in self.getStreams():
            lraw.extend(s.raw)

        return lraw

    @property
    def spectrum_streams(self):
        """ Return a flat list of spectrum streams """
        return self.get_streams_by_type(SPECTRUM_STREAMS)

    def get_streams_by_name(self, name):
        """ Return a list of streams with have names that match `name` """

        leaves = set()
        for s in self.streams:
            if isinstance(s, Stream) and s.name.value == name:
                leaves.add(s)
            elif isinstance(s, StreamTree):
                leaves |= s.get_streams_by_name(name)

        return list(leaves)

    def get_streams_by_type(self, stream_types):
        """ Return a flat list of streams of `stream_type` within the StreamTree
        """
        streams = []

        for s in self.streams:
            if isinstance(s, StreamTree):
                streams.extend(s.get_streams_by_type(stream_types))
            elif isinstance(s, stream_types):
                streams.append(s)

        return streams


class OverlayStream(object):
    """ Stream triggering the overlay procedure.

    It basically provides the necessary emitter and ccd data to find_overlay
    function.
    """

    def __init__(self, name, detector, ccd, emitter):
        """
        name (string): user-friendly name of this stream
        detector (Detector): the detector 
        ccd (Camera): the ccd 
        emitter (Emitter): the emitter
        overlay_dt (float): overlay scan grid dwell time
        overlay_rep (tuple of ints): overlay scan grid resolution
        """

        self.name = model.StringVA(name)

        # Hardware Components
        self._detector = detector
        self._emitter = emitter
        self._ccd = ccd

        self.ovrlDwellTime = model.FloatContinuous(emitter.dwellTime.range[0],
                                         range=emitter.dwellTime.range, unit="s")
        self.ovrlRepetitions = model.TupleVA((None, None))  # int, int

        # Future generated by find_overlay
        self._overlay_future = None

        self._acq_state = RUNNING

    def estimateAcquisitionTime(self):
        """ Estimate the time it will take to put through the overlay procedure

        returns (float): approximate time in seconds that overlay will take
        """
        estimated_time = find_overlay.estimateOverlayTime(self.ovrlDwellTime.value,
                                                          self.ovrlRepetitions.value)
        return estimated_time

    def acquire(self):
        """
        Just calls the FindOverlay function and obtains the corresponding 
        future 
        """
        self._overlay_future = find_overlay.FindOverlay(self.ovrlRepetitions.value,
                                                        self.ovrlDwellTime.value,
                                                        OVRL_MAX_DIFF,
                                                        self._emitter,
                                                        self._ccd,
                                                        self._detector)
        trans_val, transform_md = self._overlay_future.result()
        return transform_md

    def cancel(self):
        self._overlay_future.cancel()



